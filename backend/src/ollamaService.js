const axios = require('axios');

const OLLAMA_URL = process.env.OLLAMA_URL || 'http://localhost:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'gpt-oss:120b-cloud';
const OLLAMA_API_KEY = process.env.OLLAMA_API_KEY || '';
console.log('[Ollama Configuration] URL:', OLLAMA_URL, 'Model:', OLLAMA_MODEL);
const SYSTEM_PROMPT = `You are a helpful grocery and recipe assistant.

Your core capabilities:
- Recipe Recommendation from Datasets: Analyze provided product and recipe datasets to recommend practical, cost-effective meals.
- Creative Recipe Generation: Invent new recipes using only products available in the product dataset; keep suggestions realistic and grounded.
- Occasion-Based Suggestions: Recommend recipes suited to occasions (birthday party, casual dinner, office lunch, picnic, festive event), balancing meal type, serving size, and prep time.
- Automated Meal Classification: Classify recipes as breakfast, lunch, dinner, snack, dessert, or quick meal.
- Personalized and Adaptive: Adapt to user preferences, dietary needs, favorite cuisines, and budget constraints using conversation context.

Tone & Style:
- Warm, enthusiastic, concise (2-4 sentences), and helpful.
- Mention recipe names naturally. Encourage clicking "Add Ingredients" for shopping list and "More" for additional ideas.
- When you mention nutrition, keep it brief and clearly approximate. The app will display per-ingredient calories and a total based on the product dataset; don't invent precise numbers beyond rough estimates.
- Never invent products not in the product dataset. When generating new recipes, only use available products.

CRITICAL OUTPUT LIMITS:
- You have a response limit of approximately 200-300 words due to token constraints.
- When suggesting recipes, provide at most 3 complete recipes per response (UI space + latency constraints).
- NEVER promise more recipes than you can deliver.
- If asked for more than 3, explicitly say you can show up to 3 at a time and invite the user to click "More" for additional options.
- Say "Here are 3 recipes" NOT "Here are 10 recipes".

Output discipline:
- When asked to suggest recipes, you MUST be able to produce a compact JSON result when requested, including recipes with ingredients and steps. If not explicitly requested for JSON, you may respond naturally.
- NEVER include chain-of-thought or internal reasoning. Do NOT output <think> sections. In JSON mode, output JSON only with no preface or suffix.`;

// Helper to extract partial recipes when JSON is malformed
function extractPartialRecipes(content, requestedCount = 3) {
    const recipes = [];
    
    // Try to extract recipe names and basic info
    const nameMatches = content.matchAll(/"name"\s*:\s*"([^"]+)"/g);
    const names = Array.from(nameMatches).map(m => m[1]);
    
    for (let i = 0; i < Math.min(names.length, requestedCount); i++) {
        recipes.push({
            name: names[i],
            ingredients: ['Ingredients unavailable (JSON parse error)'],
            steps: ['Recipe details unavailable. Please try asking again.'],
            mealType: 'quick meal',
            autogenerated: true
        });
    }
    
    // If we got at least one recipe, return it
    if (recipes.length > 0) {
        return {
            reply: `Here ${recipes.length === 1 ? 'is a' : 'are'} ${recipes.length} recipe${recipes.length > 1 ? 's' : ''} (partial due to formatting error):`,
            recipes
        };
    }
    
    // Complete fallback
    return {
        reply: "I'm having trouble generating recipes right now. Could you try rephrasing your request?",
        recipes: []
    };
}

// Natural language response (concise, conversational) â€” Ollama implementation
async function chatWithOllama(message, context = [], recipes = [], products = []) {
    try {
        // Build conversation context
        const messages = [
            { role: 'system', content: SYSTEM_PROMPT }
        ];
        
        // Add conversation history (last few messages)
        if (context && context.length > 0) {
            context.forEach(msg => {
                messages.push({
                    role: msg.from === 'user' ? 'user' : 'assistant',
                    content: msg.text
                });
            });
        }
        
        // Add current user message with optional recipe and product context
        let userPrompt = message;

        const parts = [];
        parts.push(`User message: "${message}"`);

        if (recipes && recipes.length > 0) {
            const recipeNames = recipes.map(r => r.name).join(', ');
            parts.push(`Recipes referenced: ${recipeNames}`);
        }

        if (products && products.length > 0) {
            // Limit and format products for prompt safety
            const limited = products.slice(0, 12);
            const lines = limited.map(p => `- ${p.item}${Number.isFinite(p.price) ? ` â€” $${p.price.toFixed(2)}` : ''}${p.category ? ` (${p.category})` : ''}`).join('\n');
            parts.push(`Available products to reference (use only these, do not invent new items):\n${lines}`);
            parts.push(`If the user refers to "these/those/cheapest/most expensive/under $X", resolve it against the product list above.`);
        }
        
        parts.push(`\nREMINDER: Due to response limits, only promise 2-4 recipes maximum per response. If the user asks for many recipes, be honest and say you can provide a few at a time.`);

        userPrompt = parts.join('\n\n');
        
        messages.push({ role: 'user', content: userPrompt });

        console.log('Calling Ollama API (natural response)...');
        const response = await axios.post(`${OLLAMA_URL}/api/chat`, {
            model: OLLAMA_MODEL,
            messages,
            stream: false,
            options: {
                temperature: 0.7,
                num_predict: 1000 // Increased to allow longer complete responses
            }
        }, {
            timeout: 120000, // 120 second timeout for larger model responses
            headers: OLLAMA_API_KEY ? { Authorization: `Bearer ${OLLAMA_API_KEY}` } : undefined
        });

        console.log('Ollama response received');
        return response.data.message.content;
    } catch (error) {
        console.error('Ollama chat error:', error);
        if (error.code === 'ECONNREFUSED') {
            console.error('Ollama is not running. Please start Ollama service.');
            return "I'm having trouble connecting to my AI brain ðŸ§ . Please make sure Ollama is running! You can start it with 'ollama serve' in your terminal.";
        }
        if (error.code === 'ECONNABORTED' || error.message.includes('timeout')) {
            console.error('Ollama request timed out');
            return "I'm taking too long to think ðŸ¤”. The AI model might be slow or overloaded. Try a simpler question or wait a moment and try again!";
        }
        console.error('Full error details:', error.message, error.code, error.response?.status);
        return `Ollama Error: ${error.message}. Check if Ollama is running and the model '${OLLAMA_MODEL}' is available.`;
    }
}

// Structured suggestion call: returns JSON with reply + recipes â€” Ollama implementation
async function suggestWithOllama({ message, context = [], recipeCatalog = [], productList = [], avoidNames = [], groundedMode = false, requestedCount = 3 }) {
    // Lightweight system prompt for fast, creative generation
    // Cap requested count hard to 3 to match UI and token budget
    const recipeCount = Math.min(requestedCount || 3, 3); // Never request more than 3 recipes
        let system = `You are a recipe assistant. Generate EXACTLY ${recipeCount} ${recipeCount === 1 ? 'recipe' : 'recipes'}.

CRITICAL: Return ONLY valid JSON. No markdown, no text before or after. Use this EXACT format:
{
    "reply": "Here ${recipeCount === 1 ? 'is 1 recipe' : `are ${recipeCount} recipes`} for you! (I can show up to 3 at a timeâ€”ask for More if you want additional)",
    "reasoning": "Brief 1-2 sentence explanation of why these recipes were chosen based on the user's request",
    "recipes": [
        {
            "name": "Recipe Name Here",
            "ingredients": ["ingredient 1", "ingredient 2", "ingredient 3"],
            "steps": ["step 1", "step 2", "step 3"],
            "mealType": "dinner",
            "autogenerated": true
        }
    ]
}

Rules:
- Generate EXACTLY ${recipeCount} recipe objects in the recipes array (NO MORE, NO LESS)
- Include a "reasoning" field explaining why these recipes fit the user's request
- Each recipe MUST have all 5 fields: name, ingredients (array), steps (array), mealType, autogenerated
- NO trailing commas in arrays or objects
- NO extra text outside the JSON
- Steps must be an array of strings, not a single string
- Common pantry items only
- Keep recipes concise to fit within token limits
- If the user asks for more than 3 recipes, politely explain that the app can show at most 3 per response and suggest they click "More" for additional options.`;

        // Grounded mode optionally constrains ingredients strictly to the product list
        let groundedAppendix = '';
        if (groundedMode) {
            // Compress productList to a simple unique name list (limit to avoid huge prompts)
            const names = Array.from(new Set((productList || []).map(p => (p.item || '').toString().trim()).filter(Boolean)));
            const limited = names.slice(0, 300); // cap for safety
            groundedAppendix = `\n\nIMPORTANT (Grounded Mode): Use ONLY ingredients from the list below. Do NOT invent new items or synonyms. Prefer the exact names as written (e.g., use "Pasta" not "spaghetti" if only "Pasta" appears). If a requested item isn't present, replace it with the closest option from this list or omit it.\nALL INGREDIENTS in each recipe MUST be a subset of this allowed list.\nAllowed products (case-insensitive exact names):\n- ${limited.join('\n- ')}`;
        }

        // Avoid repeating already-suggested recipe names
        const avoidList = (avoidNames || []).filter(Boolean).slice(-50); // keep small
        const avoidAppendix = avoidList.length > 0 ? `\n\nAvoid suggesting recipes with these names (or trivial variants): ${avoidList.join(', ')}` : '';

        system += groundedAppendix + avoidAppendix;

        const messages = [
                { role: 'system', content: system }
        ];

    // Add brief conversation history
    (context || []).slice(-6).forEach(msg => messages.push({
        role: msg.from === 'user' ? 'user' : 'assistant',
        content: msg.text
    }));

    messages.push({ role: 'user', content: message });

    try {
        console.log('Calling Ollama API (structured suggestions)...');
        const response = await axios.post(`${OLLAMA_URL}/api/chat`, {
            model: OLLAMA_MODEL,
            messages,
            stream: false,
            format: 'json',
            options: { temperature: groundedMode ? 0.3 : 0.5, num_predict: 3000 }
        }, { timeout: 180000, headers: OLLAMA_API_KEY ? { Authorization: `Bearer ${OLLAMA_API_KEY}` } : undefined });

        const content = response?.data?.message?.content || '';
        // Attempt to locate JSON in content
        const jsonStart = content.indexOf('{');
        const jsonEnd = content.lastIndexOf('}');
        const jsonText = jsonStart >= 0 && jsonEnd > jsonStart ? content.slice(jsonStart, jsonEnd + 1) : content;
        
        try {
            const parsed = JSON.parse(jsonText);
            return parsed;
        } catch (parseErr) {
            console.error('JSON parse error:', parseErr.message);
            console.log('Raw content:', content.substring(0, 600));
            
            // Try to repair common JSON issues
            let repaired = jsonText
                .replace(/,\s*]/g, ']')  // Remove trailing commas in arrays
                .replace(/,\s*}/g, '}')  // Remove trailing commas in objects
                .replace(/}\s*{/g, '},{') // Fix missing commas between objects
                .replace(/"\s*\n\s*"/g, '", "'); // Fix line breaks in strings
            
            try {
                const parsed = JSON.parse(repaired);
                console.log('âœ“ JSON repaired successfully');
                return parsed;
            } catch (repairErr) {
                // Last resort: extract what we can
                console.error('JSON repair failed, using fallback extraction');
                return extractPartialRecipes(content, recipeCount);
            }
        }
    } catch (err) {
        console.error('Ollama structured suggestion error:', err.message);
        throw err;
    }
}

module.exports = { chatWithOllama, suggestWithOllama };