# Copy to .env and fill in your values
# LLM provider: If LLM_PROVIDER is set to 'openai', OpenAI will be used; otherwise set to 'ollama' (default if no OpenAI key).
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
LLM_PROVIDER=ollama   # or 'openai'

# Ollama configuration (local or cloud)
# Default local URL:
# OLLAMA_URL=http://localhost:11434
# To use a cloud endpoint, set OLLAMA_URL to your provider base URL and OLLAMA_API_KEY for auth
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_API_KEY=

# Server
PORT=3333
HOST=127.0.0.1
DEBUG=0
